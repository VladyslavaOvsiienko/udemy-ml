{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prescribed-absence",
   "metadata": {},
   "source": [
    "# Classification Models Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-highlight",
   "metadata": {},
   "source": [
    "About data set: this is classic data set for classification, features describe characteristics of the cell nuclei present in the image, 10 real-valued features are computed for each cell nucleus. \n",
    "The goal is diagnosis (4 = malignant, 2 = benign).\n",
    "Resource: https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-oxygen",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vietnamese-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "connected-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-liverpool",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worldwide-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('breast-cancer-wisconsin.data', \n",
    "                      names = ['ID', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', \n",
    "                                 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', \n",
    "                                 'Normal Nucleoli', 'Mitoses', 'Class' ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alien-attempt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             object\n",
       "Clump Thickness                 int64\n",
       "Uniformity of Cell Size         int64\n",
       "Uniformity of Cell Shape        int64\n",
       "Marginal Adhesion               int64\n",
       "Single Epithelial Cell Size     int64\n",
       "Bare Nuclei                    object\n",
       "Bland Chromatin                 int64\n",
       "Normal Nucleoli                 int64\n",
       "Mitoses                         int64\n",
       "Class                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "informative-coffee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-confidentiality",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-technician",
   "metadata": {},
   "source": [
    "The data set has missed values in 'Bare Nuclei' (I decided replace into mean value) and it is better encode dependent variable class - instead 2 and 4 assign 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painful-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace ? into Nan to calculate mean\n",
    "dataset['Bare Nuclei'].replace({\"?\": np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "guided-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Bare Nuclei'] = pd.to_numeric(dataset['Bare Nuclei'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rolled-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Bare Nuclei']= dataset['Bare Nuclei'].fillna(dataset['Bare Nuclei'].mean(skipna=True)).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-compound",
   "metadata": {},
   "source": [
    "## Splitting data into features and dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "senior-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:-1].values # exclude ID\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sacred-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "transdict = {2: 0, 4: 1}\n",
    "y = np.array([transdict[x] for x in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-genius",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "imperial-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-subscriber",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-orleans",
   "metadata": {},
   "source": [
    "We should use feature scaling for all models where we use distance - to avoid dominating one of the variables. Tree and forest don't need it but it won't spoil results. But all values are in range from 1 to 10, so we don't need it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-treasury",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "excellent-oasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "classifier_log_reg = LogisticRegression()\n",
    "classifier_log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unlimited-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "soviet-scanning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82,  3],\n",
       "       [ 1, 54]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "american-detroit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285714"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_log_reg = accuracy_score(y_test, y_pred)\n",
    "acc_score_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-contrast",
   "metadata": {},
   "source": [
    "Indeed, great result, only 4 wrong predictions and only one of them is second type error, lets see coeficients to see significance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "quality-remark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57437269, -0.03111522,  0.30197919,  0.38782657,  0.15825968,\n",
       "         0.40505614,  0.375729  ,  0.15414341,  0.4853966 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_log_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-strand",
   "metadata": {},
   "source": [
    "The most impact make first and 6st feature - Clump Thickness and Mitoses.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-barrel",
   "metadata": {},
   "source": [
    "# K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "variable-forestry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier_knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "clean-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "prescribed-cabin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83,  2],\n",
       "       [ 1, 54]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adjacent-preference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9785714285714285"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_knn = accuracy_score(y_test, y_pred)\n",
    "acc_score_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-support",
   "metadata": {},
   "source": [
    "k-NN beats Logisitic Regression on one observation. Five neighbours is optimal in our occasion  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-indication",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "diagnostic-adaptation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier_SVM_lin = SVC(kernel = 'linear')\n",
    "classifier_SVM_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "judicial-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_SVM_lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "retained-genesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82,  3],\n",
       "       [ 1, 54]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "economic-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285714"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_SVM_lin = accuracy_score(y_test, y_pred)\n",
    "acc_score_SVM_lin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-typing",
   "metadata": {},
   "source": [
    "Linear SVM gives result like Log. Reg., lets now see SVM with different non linear kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-kuwait",
   "metadata": {},
   "source": [
    "# Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fleet-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = ['poly', 'rbf', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "attractive-lighting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel : poly\n",
      "[[82  3]\n",
      " [ 1 54]]\n",
      "Score :  0.9714285714285714\n",
      "Kernel : rbf\n",
      "[[82  3]\n",
      " [ 1 54]]\n",
      "Score :  0.9714285714285714\n",
      "Kernel : sigmoid\n",
      "[[57 28]\n",
      " [54  1]]\n",
      "Score :  0.4142857142857143\n"
     ]
    }
   ],
   "source": [
    "for k in kernels:\n",
    "    classifier_SVM = SVC(kernel = k) \n",
    "    classifier_SVM.fit(X_train, y_train)\n",
    "    y_pred = classifier_SVM.predict(X_test)\n",
    "    \n",
    "    print('Kernel :', k)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('Score : ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-excuse",
   "metadata": {},
   "source": [
    "According to results, it is better use kernel of sigmoid or rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "loaded-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_SVM_rbf = SVC(kernel = 'rbf') #‘poly’, ‘rbf’, ‘sigmoid’,\n",
    "classifier_SVM_rbf.fit(X_train, y_train)\n",
    "y_pred = classifier_SVM_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "selected-logging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82,  3],\n",
       "       [ 1, 54]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "crude-shift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285714"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_SVM_rbf = accuracy_score(y_test, y_pred)\n",
    "acc_score_SVM_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-illustration",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "verified-transformation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    " \n",
    "classifier_Bayes = GaussianNB()\n",
    "classifier_Bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "choice-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_Bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "enclosed-blowing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80,  5],\n",
       "       [ 1, 54]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "spare-forward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571428571428572"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_bayes = accuracy_score(y_test, y_pred)\n",
    "acc_score_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-stack",
   "metadata": {},
   "source": [
    "Naive Bayes is bad in predicting 'benign' in this situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-luxury",
   "metadata": {},
   "source": [
    "# Decision Tree CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "tested-brazilian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "classifier_tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier_tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "similar-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "wanted-provincial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80,  5],\n",
       "       [ 5, 50]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "respective-fundamentals",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_tree = accuracy_score(y_test, y_pred)\n",
    "acc_score_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-baking",
   "metadata": {},
   "source": [
    "Decision tree gives worse result than previous models, it can be because of lack of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-hebrew",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ruled-trace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "classifier_forest = RandomForestClassifier(n_estimators = 5, criterion = 'gini', random_state = 0)\n",
    "classifier_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "descending-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "raised-paragraph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83,  2],\n",
       "       [ 3, 52]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "visible-technician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642857142857143"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_forest = accuracy_score(y_test, y_pred)\n",
    "acc_score_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-lyric",
   "metadata": {},
   "source": [
    "Random forest Classifier gives 97.8% with criterion gini and 5 trees, also with criterion entropy with 13 trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-stress",
   "metadata": {},
   "source": [
    "# Summarizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "deadly-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for Logistic Regression: 0.9714285714285714 % accuracy\n",
      "score for K-NN: 0.9785714285714285 % accuracy\n",
      "score for SVM linear: 0.9714285714285714 % accuracy\n",
      "score for SVM kernel: 0.9714285714285714 % accuracy\n",
      "score for Naive Bayes: 0.9571428571428572 % accuracy\n",
      "score for Decision Tree: 0.9285714285714286 % accuracy\n",
      "score for Random Forest: 0.9642857142857143 % accuracy\n"
     ]
    }
   ],
   "source": [
    "print(f\"score for Logistic Regression: {acc_score_log_reg} % accuracy\")\n",
    "print(f\"score for K-NN: {acc_score_knn} % accuracy\")\n",
    "print(f\"score for SVM linear: {acc_score_SVM_lin} % accuracy\")\n",
    "print(f\"score for SVM kernel: {acc_score_SVM_rbf} % accuracy\")\n",
    "print(f\"score for Naive Bayes: {acc_score_bayes} % accuracy\")\n",
    "print(f\"score for Decision Tree: {acc_score_tree} % accuracy\")\n",
    "print(f\"score for Random Forest: {acc_score_forest} % accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-seminar",
   "metadata": {},
   "source": [
    "As we can see, best results give k-NN, RandomForest. I would prefer k-NN if we had a lot data because it is fast and efficient, Random forest is powerful and accurate model at all, but it need more tunning hyperparameters than k-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-humanity",
   "metadata": {},
   "source": [
    "# Cross-validation and GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-tennessee",
   "metadata": {},
   "source": [
    "And now, I wanna find best hyperparameters for each model using GridSearchCV and compare their accuracy scores and see the contribution of this approach to determining the best model experimentally. After that use XgBoost and Catboost and to see if the beat results of previous models. And finding materials about best metrics in classification tasks recommend using F1-score for evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "municipal-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-milan",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "selective-recipient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-score: 0.95 \n",
      "Best Parameters: {'penalty': 'none', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'solver': ['liblinear'],'penalty': ['l1', 'l2']}, # I think it will choose liblinear because it fits for small data set\n",
    "             {'solver': ['lbfgs'],'penalty': ['none', 'l2']}]\n",
    "grid_search = GridSearchCV(estimator =  LogisticRegression(),\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'f1',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best F1-score: {:.2f} \".format(best_accuracy))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fiscal-wheel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set F1-score: 0.96 \n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(**best_parameters)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Test set F1-score: {:.2f} \".format(f1_score(y_test, classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-scout",
   "metadata": {},
   "source": [
    "# K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "arctic-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-score: 0.95 \n",
      "Best Parameters: {'metric': 'minkowski', 'n_neighbors': 7, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance'], 'metric': ['minkowski'], \n",
    "               'p': [1,2,3]}]\n",
    "grid_search = GridSearchCV(estimator =  KNeighborsClassifier(),\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'f1',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best F1-score: {:.2f} \".format(best_accuracy))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "selective-milan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set F1-score: 0.97 \n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(**best_parameters)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Test set F1-score: {:.2f} \".format(f1_score(y_test, classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-canada",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "posted-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-score: 0.95 \n",
      "Best Parameters: {'C': 0.75, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'C': [0.25, 0.5, 0.75], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75], 'kernel': ['rbf'], 'gamma': [0.1,  0.3,  0.5,  0.7, 0.9]},\n",
    "             {'C': [0.25, 0.5, 0.75], 'kernel': ['poly'], 'gamma': [0.1,  0.3,  0.5,  0.7, 0.9], \n",
    "              'degree': [2, 3, 4, 5, 6, 7], 'coef0': [0, 1, 3, 5]},\n",
    "             {'C': [0.25, 0.5, 0.75], 'kernel': ['sigmoid'], 'gamma': [0.1,  0.3,  0.5,  0.7, 0.9], \n",
    "              'coef0': [0, 1, 3, 5]}]\n",
    "grid_search = GridSearchCV(estimator =  SVC(),\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'f1',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best F1-score: {:.2f} \".format(best_accuracy))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "smart-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set F1-score: 0.96 \n"
     ]
    }
   ],
   "source": [
    "classifier = SVC(**best_parameters)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Test set F1-score: {:.2f} \".format(f1_score(y_test, classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-office",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "structural-actor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-score: 0.95 \n",
      "Best Parameters: {'var_smoothing': 0.12328467394420659}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'var_smoothing': np.logspace(0,-9, num=100)}]\n",
    "grid_search = GridSearchCV(estimator =  GaussianNB(),\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'f1',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best F1-score: {:.2f} \".format(best_accuracy))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "centered-patient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set F1-score: 0.96 \n"
     ]
    }
   ],
   "source": [
    "classifier = GaussianNB(**best_parameters)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Test set F1-score: {:.2f} \".format(f1_score(y_test, classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-lotus",
   "metadata": {},
   "source": [
    "# Decision Tree CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "committed-apparatus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-score: 0.91 \n",
      "Best Parameters: {'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'criterion': ['gini', 'entropy']}]\n",
    "grid_search = GridSearchCV(estimator =  DecisionTreeClassifier(random_state = 0),\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'f1',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best F1-score: {:.2f} \".format(best_accuracy))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "beneficial-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set F1-score: 0.91 \n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(random_state = 0, **best_parameters)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Test set F1-score: {:.2f} \".format(f1_score(y_test, classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-alloy",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "recent-constitutional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-score: 0.94 \n",
      "Best Parameters: {'criterion': 'entropy', 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'n_estimators': [5, 8, 10, 12, 15, 18, 20, 25], 'criterion': ['gini', 'entropy']} ]\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(random_state = 0),\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'f1',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best F1-score: {:.2f} \".format(best_accuracy))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "upper-housing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set F1-score: 0.96 \n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(random_state = 0, **best_parameters)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Test set F1-score: {:.2f} \".format(f1_score(y_test, classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-exhibit",
   "metadata": {},
   "source": [
    "Conclusion. So models with best hyperparameters was found and the best models with F1-score score on training are K-NN, Naive Bayes, SVM, Logistic regression and on test set the leader is K-NN. But all models has great results 0.91-0.96. Thanks to these algorithms we can be sure to choose right hyperparameters and evaluate models carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-first",
   "metadata": {},
   "source": [
    "# XgBoost and Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-symposium",
   "metadata": {},
   "source": [
    "These methods are known for their power in both regression and classification, it is interesting to see if they give the best results. The second should be good for categorical data, but the sample may be small for this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "chronic-ecuador",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-score: 0.93 \n",
      "Standard Deviation: 0.03 \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "accuracies = cross_val_score(estimator = XGBClassifier(verbosity = 0), X = X_train, y = y_train, cv = 10, scoring = 'f1')\n",
    "print(\"Best F1-score: {:.2f} \".format(accuracies.mean()))\n",
    "print(\"Standard Deviation: {:.2f} \".format(accuracies.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "marine-polymer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set F1-score: 0.96 \n"
     ]
    }
   ],
   "source": [
    "regressor = XGBClassifier()\n",
    "regressor.fit(X_train, y_train)\n",
    "print(\"Test set F1-score: {:.2f} \".format(f1_score(y_test, classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "advanced-handling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.007683\n",
      "0:\tlearn: 0.6781819\ttotal: 158ms\tremaining: 2m 38s\n",
      "200:\tlearn: 0.0594538\ttotal: 516ms\tremaining: 2.05s\n",
      "400:\tlearn: 0.0270740\ttotal: 839ms\tremaining: 1.25s\n",
      "600:\tlearn: 0.0161270\ttotal: 1.17s\tremaining: 779ms\n",
      "800:\tlearn: 0.0106805\ttotal: 1.5s\tremaining: 373ms\n",
      "999:\tlearn: 0.0075683\ttotal: 1.82s\tremaining: 0us\n",
      "Learning rate set to 0.007683\n",
      "0:\tlearn: 0.6788662\ttotal: 1.82ms\tremaining: 1.81s\n",
      "200:\tlearn: 0.0732659\ttotal: 329ms\tremaining: 1.31s\n",
      "400:\tlearn: 0.0374880\ttotal: 652ms\tremaining: 974ms\n",
      "600:\tlearn: 0.0229140\ttotal: 985ms\tremaining: 654ms\n",
      "800:\tlearn: 0.0153208\ttotal: 1.32s\tremaining: 327ms\n",
      "999:\tlearn: 0.0108368\ttotal: 1.64s\tremaining: 0us\n",
      "Learning rate set to 0.007683\n",
      "0:\tlearn: 0.6787709\ttotal: 1.73ms\tremaining: 1.73s\n",
      "200:\tlearn: 0.0698130\ttotal: 328ms\tremaining: 1.3s\n",
      "400:\tlearn: 0.0342041\ttotal: 656ms\tremaining: 980ms\n",
      "600:\tlearn: 0.0211700\ttotal: 982ms\tremaining: 652ms\n",
      "800:\tlearn: 0.0140734\ttotal: 1.41s\tremaining: 351ms\n",
      "999:\tlearn: 0.0099887\ttotal: 1.83s\tremaining: 0us\n",
      "Learning rate set to 0.007683\n",
      "0:\tlearn: 0.6792256\ttotal: 2.02ms\tremaining: 2.01s\n",
      "200:\tlearn: 0.0734338\ttotal: 414ms\tremaining: 1.65s\n",
      "400:\tlearn: 0.0370714\ttotal: 750ms\tremaining: 1.12s\n",
      "600:\tlearn: 0.0227110\ttotal: 1.08s\tremaining: 717ms\n",
      "800:\tlearn: 0.0151760\ttotal: 1.41s\tremaining: 350ms\n",
      "999:\tlearn: 0.0107558\ttotal: 1.75s\tremaining: 0us\n",
      "Learning rate set to 0.007683\n",
      "0:\tlearn: 0.6775352\ttotal: 1.81ms\tremaining: 1.81s\n",
      "200:\tlearn: 0.0737568\ttotal: 329ms\tremaining: 1.31s\n",
      "400:\tlearn: 0.0372404\ttotal: 662ms\tremaining: 989ms\n",
      "600:\tlearn: 0.0229570\ttotal: 1.02s\tremaining: 680ms\n",
      "800:\tlearn: 0.0156378\ttotal: 1.36s\tremaining: 337ms\n",
      "999:\tlearn: 0.0111613\ttotal: 1.71s\tremaining: 0us\n",
      "Learning rate set to 0.007683\n",
      "0:\tlearn: 0.6789431\ttotal: 1.82ms\tremaining: 1.82s\n",
      "200:\tlearn: 0.0736477\ttotal: 326ms\tremaining: 1.3s\n",
      "400:\tlearn: 0.0370373\ttotal: 664ms\tremaining: 992ms\n",
      "600:\tlearn: 0.0230369\ttotal: 1.01s\tremaining: 671ms\n",
      "800:\tlearn: 0.0156304\ttotal: 1.35s\tremaining: 336ms\n",
      "999:\tlearn: 0.0110769\ttotal: 1.68s\tremaining: 0us\n",
      "Learning rate set to 0.007683\n",
      "0:\tlearn: 0.6793165\ttotal: 1.82ms\tremaining: 1.82s\n",
      "200:\tlearn: 0.0733457\ttotal: 331ms\tremaining: 1.32s\n",
      "400:\tlearn: 0.0368617\ttotal: 663ms\tremaining: 991ms\n",
      "600:\tlearn: 0.0220658\ttotal: 1000ms\tremaining: 664ms\n",
      "800:\tlearn: 0.0146921\ttotal: 1.32s\tremaining: 329ms\n",
      "999:\tlearn: 0.0103033\ttotal: 1.65s\tremaining: 0us\n",
      "Learning rate set to 0.007683\n",
      "0:\tlearn: 0.6788036\ttotal: 1.82ms\tremaining: 1.82s\n",
      "200:\tlearn: 0.0720984\ttotal: 342ms\tremaining: 1.36s\n",
      "400:\tlearn: 0.0352973\ttotal: 667ms\tremaining: 997ms\n",
      "600:\tlearn: 0.0218036\ttotal: 991ms\tremaining: 658ms\n",
      "800:\tlearn: 0.0145294\ttotal: 1.32s\tremaining: 328ms\n",
      "999:\tlearn: 0.0103424\ttotal: 1.65s\tremaining: 0us\n",
      "Learning rate set to 0.007683\n",
      "0:\tlearn: 0.6788044\ttotal: 1.84ms\tremaining: 1.84s\n",
      "200:\tlearn: 0.0758950\ttotal: 326ms\tremaining: 1.3s\n",
      "400:\tlearn: 0.0386852\ttotal: 653ms\tremaining: 975ms\n",
      "600:\tlearn: 0.0241527\ttotal: 986ms\tremaining: 654ms\n",
      "800:\tlearn: 0.0162677\ttotal: 1.31s\tremaining: 326ms\n",
      "999:\tlearn: 0.0115996\ttotal: 1.64s\tremaining: 0us\n",
      "Learning rate set to 0.007689\n",
      "0:\tlearn: 0.6782576\ttotal: 1.81ms\tremaining: 1.81s\n",
      "200:\tlearn: 0.0764973\ttotal: 338ms\tremaining: 1.34s\n",
      "400:\tlearn: 0.0397920\ttotal: 669ms\tremaining: 999ms\n",
      "600:\tlearn: 0.0251750\ttotal: 1s\tremaining: 667ms\n",
      "800:\tlearn: 0.0170401\ttotal: 1.33s\tremaining: 332ms\n",
      "999:\tlearn: 0.0121878\ttotal: 1.68s\tremaining: 0us\n",
      "Best F1-score: 0.96 \n",
      "Standard Deviation: 0.04 \n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "accuracies = cross_val_score(estimator = CatBoostClassifier(metric_period = 200), X = X_train, y = y_train, cv = 10, scoring = 'f1')\n",
    "print(\"Best F1-score: {:.2f} \".format(accuracies.mean()))\n",
    "print(\"Standard Deviation: {:.2f} \".format(accuracies.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "living-shopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.008037\n",
      "0:\tlearn: 0.6778431\ttotal: 6.03ms\tremaining: 6.02s\n",
      "200:\tlearn: 0.0698486\ttotal: 392ms\tremaining: 1.56s\n",
      "400:\tlearn: 0.0357454\ttotal: 728ms\tremaining: 1.09s\n",
      "600:\tlearn: 0.0221856\ttotal: 1.07s\tremaining: 708ms\n",
      "800:\tlearn: 0.0146790\ttotal: 1.42s\tremaining: 353ms\n",
      "999:\tlearn: 0.0104182\ttotal: 1.76s\tremaining: 0us\n",
      "Test set F1-score: 0.96 \n"
     ]
    }
   ],
   "source": [
    "regressor = CatBoostClassifier(metric_period = 200)\n",
    "regressor.fit(X_train, y_train)\n",
    "print(\"Test set F1-score: {:.2f} \".format(f1_score(y_test, classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-clinton",
   "metadata": {},
   "source": [
    "Conclusion. XGBClassifier and CatBoostClassifier didn't beat k-NN F1-score it can be explained by a small sample of observations, but usually they are best ones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
